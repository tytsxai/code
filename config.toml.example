# Codex Configuration Example
# Copy this file to ~/.code/config.toml and customize as needed

#############################################
# 推荐默认配置 (Recommended Defaults)
#############################################

# 模型设置 (Model Settings)
model = "gpt-5.2"                    # 最强模型
model_reasoning_effort = "xhigh"       # 推理力度: minimal/low/medium/high/xhigh

# 权限设置 (Permission Settings)
approval_policy = "untrusted"          # 非内置白名单命令前提示审批
sandbox_mode = "workspace-write"       # 仅允许当前工作区可写，限制网络

# 语言/本地化 (Language / Locale)
ui_locale = "en-US"                    # 默认英文；设为 "zh-CN" 可切换为中文

# 性能设置 (Performance Settings)
enable_compaction = true               # 自动压缩长对话
disable_response_storage = true        # 不存储响应（节省空间）

# Auto Drive 设置 (Auto Drive Settings)
[auto_drive]
model = "gpt-5.2"                      # Auto Drive 使用的模型
model_reasoning_effort = "xhigh"        # Auto Drive 推理力度
# use_chat_model = true                # 或者跟随聊天模型
parallel_instances = 1                  # 并行实例数（1-5）：>1 时同模型多实例并发执行

# 增强功能设置 (Enhanced Features - Experimental)
# checkpoint_enabled = false           # 启用检查点持久化
# checkpoint_dir = "~/.code/checkpoints"  # 检查点存储目录
# checkpoint_interval = 5              # 每 N 轮保存一次检查点

# diagnostics_enabled = true           # 启用诊断引擎
# loop_threshold = 3                   # 循环检测阈值（连续相同调用次数）

# token_budget = 100000                # Token 预算限制
# turn_limit = 50                      # 最大轮次限制
# duration_limit_seconds = 3600        # 最大执行时长（秒）

# max_concurrent_agents = 8            # 最大并发智能体数（默认 8，满足 8 角色并行）

# 高吞吐池设置 (High Throughput Pool)
# [auto_drive.high_throughput]
# max_sessions = 20                    # 会话池最大并发
# min_sessions = 5                     # 预热的最小会话数
# scale_up_threshold = 0.8             # 利用率达到 80% 时扩容
# scale_down_threshold = 0.3           # 利用率低于 30% 时收缩
# backpressure_multiplier = 10         # 队列背压阈值 = max_sessions * multiplier

# audit_enabled = false                # 启用审计日志
# audit_path = "~/.code/audit.json"    # 审计日志路径

# telemetry_enabled = false            # 启用遥测收集

#############################################

# Agent Configuration
# Configure which external AI models are available and their settings
[[agents]]
name = "claude"
command = "claude"
enabled = false
read-only = false
description = "Claude AI assistant with full capabilities"
args = ["--dangerously-skip-permissions"]

[[agents]]
name = "claude-safe"
command = "claude"
enabled = false
read-only = true
description = "Claude AI assistant in read-only mode"
args = []

[[agents]]
name = "gemini"
command = "gemini"
enabled = false
read-only = false
description = "Google Gemini AI assistant"
args = ["-y"]

[[agents]]
name = "gemini-safe"
command = "gemini"
enabled = false
read-only = true
description = "Google Gemini AI assistant in read-only mode"
args = []

[[agents]]
name = "qwen"
command = "qwen"
enabled = false
read-only = false
description = "Qwen Coder assistant (tracks latest default model)"
# No default -m: let the CLI choose its current default model
# To pin a model explicitly, export QWEN_MODEL or add here, e.g.:
# args = ["-m", "qwen-3-coder", "-y"]
args = ["-y"]
# Optional environment variables (either name works; mirrored automatically):
# env = { QWEN_API_KEY = "your-key", DASHSCOPE_API_KEY = "your-key" }

[[agents]]
name = "qwen-safe"
command = "qwen"
enabled = false
read-only = true
description = "Qwen Coder assistant in read-only mode"
# No -y in read-only; omit -m to track latest default. To pin:
# args = ["-m", "qwen-3-coder"]
args = []

[[agents]]
name = "codex"
command = "codex"
enabled = false
read-only = false
description = "Codex AI assistant (self-referential)"
args = ["-s", "workspace-write", "-a", "never"]

[[agents]]
name = "context-collector"
command = "gemini"
enabled = false
read-only = true
description = "Gemini 2.5 long-context helper for repository sweeps"
# Supply the long-context model and default yes flag
args = ["-y", "--model", "gemini-2.5-pro-exp"]
# Optional: pass API key overrides or helper tool environment
# env = { GEMINI_API_KEY = "your-key", STATIC_ANALYZER = "scripts/blast-radius" }

[[agents]]
name = "gpt-4"
command = "gpt"
enabled = false
read-only = false
description = "OpenAI GPT-4 assistant"
args = ["--model", "gpt-4"]
# Optional environment variables for the agent
# env = { OPENAI_API_KEY = "your-key-here" }

# Custom agent example
[[agents]]
name = "custom-llm"
command = "/usr/local/bin/custom-llm"
enabled = false
read-only = false
description = "Custom LLM implementation"
args = ["--config", "/path/to/config.json"]
env = { MODEL_PATH = "/models/custom.bin", TEMP = "0.7" }

# Cloud agent example
[[agents]]
name = "cloud"    # keep name = "cloud" so built-in /plan,/solve default lists include it
command = "cloud"  # can be any CLI or path (e.g., "cloud-agent"); behavior keys off the agent name
enabled = false
read-only = true   # cloud work typically runs remotely; local writes aren't needed
description = "Submit tasks to a remote cloud worker"
# By default no extra flags are passed; the prompt is appended positionally.
# If your CLI expects a flag before the prompt, specify it here, e.g.:
# args = ["submit", "-p"]
# Optional environment:
# env = { CODEX_CLOUD_ENV = "prod" }

# Windows-specific agent configuration examples
# On Windows, it's recommended to use absolute paths to avoid PATH issues.
# Typical npm global install location: C:\Users\YourUser\AppData\Roaming\npm\

# [[agents]]
# name = "claude"
# command = "C:\\Users\\YourUser\\AppData\\Roaming\\npm\\claude.cmd"
# enabled = true
# description = "Claude AI assistant (Windows absolute path)"
# args = ["--dangerously-skip-permissions"]

# [[agents]]
# name = "gemini"
# command = "C:\\Users\\YourUser\\AppData\\Roaming\\npm\\gemini.cmd"
# enabled = true
# description = "Gemini assistant (Windows absolute path)"
# args = ["-y"]
# env = { GEMINI_API_KEY = "your-key-here" }

# [[agents]]
# name = "coder"
# command = "C:\\Users\\YourUser\\AppData\\Roaming\\npm\\coder.cmd"
# enabled = true
# description = "Code assistant (Windows absolute path)"
# args = ["-y"]

# Note: Replace "YourUser" with your actual Windows username.
# To find your npm global install location, run: npm config get prefix

# Sandbox Configuration
# Controls file system access and permissions
# Uncomment to override the recommended defaults above.
# sandbox_mode = "workspace-write"
#
# [sandbox_workspace_write]
# writable_roots = ["."]
# network_access = true
# exclude_tmpdir_env_var = false
# exclude_slash_tmp = false

# Shell Environment Configuration
[shell_environment_policy]
inherit = "all"
ignore_default_excludes = false
# Exclude sensitive environment variables
exclude = ["*SECRET*", "*PASSWORD*", "*CREDENTIAL*"]
# Set custom environment variables
set = { EDITOR = "vim", PAGER = "less" }

# History Configuration
[history]
persistence = "save-all"
max-bytes = 10485760  # 10MB

# Notice acknowledgement flags
[notice]
hide_gpt5_1_migration_prompt = false
hide_gpt-5.1-codex-max_migration_prompt = false

# TUI settings
[tui]
# Set to false if你需要用终端自带的滚动（例如鼠标滚轮/触控板）而不是 PageUp/PageDown。
# 默认 true（全屏模式，滚动需用 PageUp/PageDown 或鼠标事件）。
alternate_screen = true

# TUI Theme Configuration
# Available themes (built-ins):
# light-photon, light-photon-ansi16, light-prism-rainbow, light-vivid-triad,
# light-porcelain, light-sandbar, light-glacier,
# dark-carbon-night, dark-carbon-ansi16, dark-shinobi-dusk, dark-oled-black-pro,
# dark-amber-terminal, dark-aurora-flux, dark-charcoal-rainbow, dark-zen-garden,
# dark-paper-light-pro, custom
[tui.theme]
name = "dark-carbon-night"  # 深色主题

# MCP Server Configuration
# Example MCP server configurations
[mcp_servers.example-server]
command = "npx"
args = ["-y", "@example/mcp-server"]
env = { API_KEY = "your-api-key" }

# File Opener Configuration
file_opener = "vscode"  # Options: vscode, vscode-insiders, windsurf, cursor, none

# Subagent Commands
# Configure built-in and custom multi-agent slash commands.
# Each entry overrides defaults when the `name` matches a built-in: plan | solve | code.
#
# Fields:
# - name: command name (e.g., "plan")
# - read-only: true for read-only (default: plan/solve=true, code=false)
# - agents: array of agent names; if empty, falls back to enabled [[agents]] or built-ins
# - orchestrator-instructions: extra instructions appended to Code (the coordinator)
# - agent-instructions: extra instructions appended to each agent’s prompt

[subagents]

[[subagents.commands]]
name = "plan"
read-only = true
agents = ["claude", "gemini", "qwen"]
orchestrator-instructions = "Focus on discovering project layout and risks. Prefer small, verifiable steps."
agent-instructions = "Summarize assumptions explicitly. Cite files you read."

[[subagents.commands]]
name = "solve"
read-only = true
agents = ["claude", "gemini", "qwen"]
orchestrator-instructions = "Run multiple approaches in parallel and compare. Defer cancellation until a tested fix exists."
agent-instructions = "Propose a concrete fix with steps to validate."

[[subagents.commands]]
name = "code"
read-only = false
agents = ["claude", "gemini", "qwen"]
orchestrator-instructions = "Coordinate implementations across agents; surface worktree locations and branches."
agent-instructions = "Write minimal, focused changes with clear rationale. Include test or validation steps."

[[subagents.commands]]
name = "context"
read-only = true
agents = ["context-collector", "codex"]
orchestrator-instructions = "Launch a context sweep before coding. Aggregate file summaries and tooling hints for the main agent."
agent-instructions = "Summarize high-signal files, why they matter, and recommended analysis commands. Keep replies concise."

# Custom example
[[subagents.commands]]
name = "review"
read-only = true
agents = ["claude", "gemini", "qwen"]
orchestrator-instructions = "Perform a multi-agent code review; reconcile disagreements into actionable feedback."
agent-instructions = "Provide inline comments, cite files/lines, and suggest precise diffs."
